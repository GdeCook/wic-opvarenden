{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIC-Opvarenden: main script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we import necessary libraries\n",
    "\n",
    "# .. for reading and working with files\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "# ... for reading Page XML-files and coordinates\n",
    "from pagexml.parser import parse_pagexml_file\n",
    "from shapely.geometry import Polygon, box\n",
    "\n",
    "# ... for searching within deed texts\n",
    "from fuzzy_search.fuzzy_phrase_searcher import FuzzyPhraseSearcher\n",
    "from fuzzy_search.fuzzy_phrase_model import PhraseModel\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read index of person names in Schaef notarial (transport) deeds\n",
    "# This file includes information on the coordinates of the person names\n",
    "index_schaef = {}\n",
    "with open('../data/index/schaef_transport_20230329.csv') as f:\n",
    "    for c, line in enumerate(csv.DictReader(f)):\n",
    "        index_schaef[c] = dict(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read index of location names in all notarial deeds\n",
    "# This file includes information on the coordinates of the location names\n",
    "locations = {}\n",
    "with open('../data/index/locations.csv') as f:\n",
    "    for c, line in enumerate(csv.DictReader(f)):\n",
    "        # Get deed URI\n",
    "        id = line['id'].split('?location')\n",
    "        deed_uri = id[0]\n",
    "        try:\n",
    "            location_id = id[1].lstrip('=')\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        if deed_uri in locations:\n",
    "            uricount += 1\n",
    "        else:\n",
    "            uricount = 0\n",
    "            locations[deed_uri] = {}  \n",
    "        \n",
    "        locations[deed_uri][location_id] = {}\n",
    "        locations[deed_uri][location_id]['label'] = line['label']\n",
    "        locations[deed_uri][location_id]['xywh'] = line['xywh']\n",
    "        locations[deed_uri][location_id]['scanname'] = line['scanname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse index Schaef to give every deed its own key\n",
    "# In the current version of the GA data model, there is no link between annotations and individual deeds\n",
    "# So, a scan with multiple deeds will have multiple coordinates for the same person name\n",
    "# Therefore, I store all coordinates for a person name in a deed in a list\n",
    "index_schaef_per_deed = {}\n",
    "\n",
    "for k, v in index_schaef.items():\n",
    "    uri = v['akteIndex']\n",
    "    \n",
    "    if uri not in index_schaef_per_deed:\n",
    "        index_schaef_per_deed[uri] = {}\n",
    "        index_schaef_per_deed[uri]['date'] = v['date']\n",
    "        index_schaef_per_deed[uri]['subject'] = v['onderwerpsomschrijving']\n",
    "        index_schaef_per_deed[uri]['persons'] = {}\n",
    "\n",
    "    person = v['person']\n",
    "\n",
    "    if person not in index_schaef_per_deed[uri]['persons']:\n",
    "        index_schaef_per_deed[uri]['persons'][person] = {}\n",
    "        index_schaef_per_deed[uri]['persons'][person]['label'] = v['personName']\n",
    "        index_schaef_per_deed[uri]['persons'][person]['coordinates'] = [(v['coordinates'], v['scanName'])]\n",
    "\n",
    "    else:\n",
    "        index_schaef_per_deed[uri]['persons'][person]['coordinates'].append((v['coordinates'], v['scanName']))\n",
    "\n",
    "# Add location information per deed        \n",
    "for k,v in index_schaef_per_deed.items():\n",
    "    \n",
    "    if k in locations:\n",
    "        \n",
    "        # Add location dict for this key to index_schaef_per_deed\n",
    "       current_location = locations[k]\n",
    "       index_schaef_per_deed[k]['locations'] = {}\n",
    "\n",
    "       for loc in current_location:\n",
    "           loc_uri = str(k) + '?location=' + str(loc)\n",
    "           index_schaef_per_deed[k]['locations'][loc_uri] = {}\n",
    "           index_schaef_per_deed[k]['locations'][loc_uri]['label'] = current_location[loc]['label']\n",
    "           index_schaef_per_deed[k]['locations'][loc_uri]['coordinates'] = [(current_location[loc]['xywh'], current_location[loc]['scanname'])]\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(box_coord, target_coord, margin=0):\n",
    "    \"\"\"\n",
    "    Function to determine if coordinates overlap. Uses Shapely's Polygon class.\n",
    "    The function returns 1 if there is overlap, otherwise 0.\n",
    "    \n",
    "    box_coord: the coordinates of the box (i.e. a textline).\n",
    "    target_coord: the coordinates of the target (i.e. a name).\n",
    "    margin: the margin by which the target is enlarged for better matching.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Make Shapely polygon from box coordinates\n",
    "    polygon = Polygon(box_coord)\n",
    "\n",
    "    #Check if there is overlap\n",
    "    return polygon.intersects(target_coord)\n",
    "\n",
    "def calculate_bounding_rectangle(list_of_coordinates):\n",
    "    \"\"\"\n",
    "    Function to calculate the overarching bounding rectangle of a list of coordinates.\n",
    "    \"\"\"\n",
    "    all_points = [point for coordinates in list_of_coordinates for point in coordinates]\n",
    "\n",
    "    min_x = min(point[0] for point in all_points)\n",
    "    max_x = max(point[0] for point in all_points)\n",
    "    min_y = min(point[1] for point in all_points)\n",
    "    max_y = max(point[1] for point in all_points)\n",
    "\n",
    "    bounding_rectangle = [[min_x, min_y], [max_x, min_y], [max_x, max_y], [min_x, max_y]] #List of lists instead of tuples for easy transfer to JS code later\n",
    "\n",
    "    return bounding_rectangle\n",
    "\n",
    "def check_for_empty(input_data):\n",
    "    if isinstance(input_data, str):\n",
    "        # Checks if string is alphanumeric\n",
    "        if input_data.isalnum():\n",
    "            return input_data\n",
    "        else:\n",
    "            return None\n",
    "    # Checks if input is a list\n",
    "    elif isinstance(input_data, list):\n",
    "        # Goes through the list and checks each element\n",
    "        new_list = [x if x.isalnum() else None for x in input_data]\n",
    "        # If the list contains only Nones, return None\n",
    "        if all(x is None for x in new_list):\n",
    "            return None\n",
    "        else:\n",
    "            return new_list\n",
    "    else:\n",
    "        raise TypeError(\"Input must be a string or a list of strings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a prepared list of ship names\n",
    "# This list was prepared used the manual index of the Schaef deeds\n",
    "schepen_set = set()\n",
    "\n",
    "filename = '../data/index/schaef_ships.csv'\n",
    "\n",
    "with open(filename, 'r') as csvfile:\n",
    "    datareader = csv.reader(csvfile)\n",
    "    for row in datareader:\n",
    "        if row:\n",
    "            scheepsnaam = row[0]\n",
    "            scheepsnaam = scheepsnaam.rstrip().lower()\n",
    "            schepen_set.add(scheepsnaam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image_url dict from a pickle file\n",
    "with open('../data/index/image_url.pickle', 'rb') as handle:\n",
    "    image_url = pickle.load(handle)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config\n",
    "Shortcut to [loop](#loop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config for the various formulaic pattern searchers\n",
    "\n",
    "# Config for sailor searcher (\"varende voor\")\n",
    "config = {\n",
    "    \"char_match_threshold\": 0.8,\n",
    "    \"ngram_threshold\": 0.6,\n",
    "    \"levenshtein_threshold\": 0.7,\n",
    "    \"ignorecase\": True,\n",
    "    \"ngram_size\": 2,\n",
    "    \"skip_size\": 2,\n",
    "}\n",
    "\n",
    "# Config for sailor name searcher (fuzzy search for sailor names mentioned in the index)\n",
    "config2 = {\n",
    "    \"char_match_threshold\": 0.6,\n",
    "    \"ngram_threshold\": 0.5,\n",
    "    \"levenshtein_threshold\": 0.5,\n",
    "    \"ignorecase\": True,\n",
    "    \"ngram_size\": 2,\n",
    "    \"skip_size\": 2,\n",
    "}\n",
    "\n",
    "# Config for location searcher (fuzzy search for location names mentioned in the index)\n",
    "config3 = {\n",
    "    \"char_match_threshold\": 0.6,\n",
    "    \"ngram_threshold\": 0.5,\n",
    "    \"levenshtein_threshold\": 0.5,\n",
    "    \"ignorecase\": True,\n",
    "    \"ngram_size\": 2,\n",
    "    \"skip_size\": 2,\n",
    "}\n",
    "\n",
    "# Set signal phrases for sailor searcher\n",
    "sailor_searcher = FuzzyPhraseSearcher(config)\n",
    "sailor_phrases = [\n",
    "    \"varende voor\",\n",
    "    \"vare voor\",\n",
    "    \"estvarende voor\",\n",
    "    \"oouvarende voor\",\n",
    "    \"van voor\",\n",
    "    \"voren opt' schip\",\n",
    "]\n",
    "sailor_model = PhraseModel(phrases=sailor_phrases)\n",
    "sailor_searcher.index_phrase_model(sailor_model)\n",
    "\n",
    "# Alternative sailor searcher if the first one doesn't find anything\n",
    "sailor_alt_searcher = FuzzyPhraseSearcher(config)\n",
    "sailor_alt_phrases = [\"onder capitein\", \"onder cap\", \"gaende voor\", \"varen na\", \"varen voor\", \"opt schip\", \"op t' schif\"]\n",
    "sailor_alt_model = PhraseModel(phrases=sailor_alt_phrases)\n",
    "sailor_alt_searcher.index_phrase_model(sailor_alt_model)\n",
    "\n",
    "sailor_name_searcher = FuzzyPhraseSearcher(config2)\n",
    "location_searcher = FuzzyPhraseSearcher(config3)\n",
    "\n",
    "# Set no sailor job phrases for sailor job searcher (after these phrases, the job is not mentioned)\n",
    "no_sailor_job_phrases = [\"voren opt' schip\", \"onder capitein\", \"onder cap\", \"varen na\", \"opt schip\", \"op t' schif\"]\n",
    "\n",
    "# Set pattern to extract ship names and organizations using regex\n",
    "ship_pattern = r\"(?:op|opt|op't|op t) ('t )?(\\b(?:schip|Schip)\\b\\s*(?:de|d')?\\s*\\w+(?:\\s*\\w+)?)\"\n",
    "org_pattern = r\"(?:\\b(?:Oost|West|west)[-\\s]?Ind(?:e|ische)(?:[.]? Comp.?)?\\b)\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Deed:\n",
    "    \"\"\"\n",
    "    The Deed class represents a notarial deed with associated metadata, persons, and locations.\n",
    "    It contains methods for retrieving the corresponding PageXML and extracting the first few lines of the deed.\n",
    "    \"\"\"\n",
    "\n",
    "    # Add notarial deeds as a class attribute\n",
    "    # This is a dict with deed URIs as keys and metadata as values\n",
    "    notarial_deeds = {}\n",
    "    with open('../data/index/records.csv') as f:\n",
    "        for line in csv.DictReader(f):\n",
    "            notarial_deeds[line['id']] = dict(line)\n",
    "\n",
    "\n",
    "    def __init__(self, deed_uri, date=None, subject=None, persons=None, locations=None):\n",
    "        self.deed_uri = deed_uri\n",
    "        self.persons = []\n",
    "        self.locations = []\n",
    "\n",
    "        if date:\n",
    "            self.date = date\n",
    "\n",
    "        if subject:\n",
    "            self.subject = subject\n",
    "\n",
    "        if persons:\n",
    "            for person_uri, person_data in persons.items():\n",
    "                person = Person(\n",
    "                    person_uri,\n",
    "                    person_data['label'],\n",
    "                    person_data['coordinates']\n",
    "                )\n",
    "                self.persons.append(person)\n",
    "\n",
    "        if locations:\n",
    "            for location_uri, location_data in locations.items():\n",
    "                location = Location(\n",
    "                    location_uri, \n",
    "                    location_data['label'],\n",
    "                    location_data['coordinates']\n",
    "                )\n",
    "                self.locations.append(location)\n",
    "\n",
    "\n",
    "    def get_pagexml(self):\n",
    "        \"\"\"\n",
    "        Locates a deed from the instance's deed_uri.\n",
    "        It looks for the deed in a local folder.\n",
    "        Returns a parsed version of the Page XML of the first deed page if successful, otherwise None.\n",
    "        \"\"\"\n",
    "        begin_scanname = None\n",
    "\n",
    "        # The deed should be in the index of notarial deeds ...\n",
    "        if self.deed_uri in self.notarial_deeds:\n",
    "            begin_scanname = self.notarial_deeds[self.deed_uri]['begin_scanname']\n",
    "\n",
    "        if not begin_scanname:\n",
    "            return None\n",
    "\n",
    "        # Convert scanname to xml-filename\n",
    "        scan = begin_scanname[:-6]\n",
    "        page = int(begin_scanname[-6:])\n",
    "        filename = str(scan) + str(page).zfill(6) + \".xml\"\n",
    "\n",
    "        # Look for the file in the local folder\n",
    "        if not os.path.exists(f'../data/pagexml/{filename}'):\n",
    "            print(\"File not found!\")\n",
    "            raise FileNotFoundError\n",
    "\n",
    "        # Get image URL\n",
    "        if filename in image_url:\n",
    "            this_image_url = image_url[filename]\n",
    "        else:\n",
    "            this_image_url = None\n",
    "\n",
    "        current = parse_pagexml_file(f'../data/pagexml/{filename}')\n",
    "\n",
    "        return current, this_image_url\n",
    "\n",
    "\n",
    "    def get_first_lines(self, pagexml):\n",
    "        \"\"\"\n",
    "        Returns the first few lines of a deed. \n",
    "        It tries to estimate the start of the deed by looking at its begin_coordinates.\n",
    "        If there are no known begin coordinates, the function returns None.\n",
    "\n",
    "        pagexml: the deed PageXML\n",
    "        \"\"\"\n",
    "\n",
    "        deed = self.deed_uri\n",
    "        if deed in self.notarial_deeds:\n",
    "            begin_coordinates = self.notarial_deeds[deed]['begin_coordinates']\n",
    "            begin_coordinates = [int(x) for x in begin_coordinates.split(',')]\n",
    "            dimensions = pagexml.coords.points\n",
    "            width = dimensions[1][0]\n",
    "            height = dimensions[2][1]\n",
    "\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "        # Set the box size and estimate the middle of the scan\n",
    "        box_depth = 1500\n",
    "        halfpage_mark = width / 2 - 150\n",
    "        \n",
    "        # If the begin coordinates are on the left side of the page, the first lines are on the left side\n",
    "        if begin_coordinates[0] < (halfpage_mark):\n",
    "            right_boundary = halfpage_mark\n",
    "            first_line_box = box(begin_coordinates[0], begin_coordinates[1], halfpage_mark, begin_coordinates[1]+box_depth)\n",
    "        \n",
    "        # If the begin coordinates are on the right side of the page, the first lines are on the right side\n",
    "        else:\n",
    "            right_boundary = width\n",
    "            first_line_box = box(begin_coordinates[0], begin_coordinates[1], right_boundary, begin_coordinates[1]+box_depth)\n",
    "       \n",
    "        # Now that we have the box, we can extract the text (using the overlap function)\n",
    "        fulltext = []\n",
    "        fullcoords = []\n",
    "        for line in pagexml.get_lines():\n",
    "            textlinecoord = line.coords.points\n",
    "            if line.text is not None:\n",
    "\n",
    "                if overlap(textlinecoord, first_line_box, margin=100):\n",
    "                    fulltext.append(line.text)\n",
    "                    fullcoords.append(textlinecoord)\n",
    "\n",
    "        fulltext = \" \".join(fulltext)\n",
    "        \n",
    "        return(fulltext, fullcoords, [width, height])\n",
    "\n",
    "\n",
    "class Person:\n",
    "    \"\"\"\n",
    "    The Person class represents a person mentioned in a deed with a unique URI, label (name), and coordinates.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, person_uri, label, coordinates):\n",
    "        self.person_uri = person_uri\n",
    "        self.label = label\n",
    "        self.coordinates = coordinates\n",
    "\n",
    "\n",
    "class Location:\n",
    "    \"\"\"\n",
    "    The Location class represents a location mentioned in a deed with a unique URI, label (name), and coordinates.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, location_uri, label, coordinates):\n",
    "        self.location_uri = location_uri\n",
    "        self.label = label\n",
    "        self.coordinates = coordinates\n",
    "\n",
    "\n",
    "class Sailor:\n",
    "    \"\"\"\n",
    "    The Sailor class represents a sailor with a reference to the corresponding deed, and metadata such as URI, name, location, role, organization, and ship name.\n",
    "    It also contains a dictionary 'check' to store algorithm input for manual verification of the output.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, deed, sailor_uri=None, name=None, location=None, location_uri=None, location_htr=None, role=None, role_htr=None, organization=None, organization_htr=None, shipname=None, shipname_htr=None):\n",
    "        self.deed = deed\n",
    "        self.sailor_uri = sailor_uri\n",
    "        self.name = name\n",
    "        self.location = location\n",
    "        self.location_uri = location_uri\n",
    "        self.location_htr = location_htr\n",
    "        self.role = role\n",
    "        self.role_htr = role_htr\n",
    "        self.organization = organization\n",
    "        self.organization_htr = organization_htr\n",
    "        self.shipname = shipname\n",
    "        self.shipname_htr = shipname_htr\n",
    "        self.check = {} # Dictionary to store algorithm input for manual check\n",
    "\n",
    "\n",
    "\n",
    "class SailorExtractor:\n",
    "    \"\"\"\n",
    "    The SailorExtractor class is responsible for extracting sailors from a list of Deed objects.\n",
    "    It contains a method 'extract_sailors' which processes the deeds and extracts Sailor instances with the corresponding metadata.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, deeds):\n",
    "        self.deeds = deeds\n",
    "        \n",
    "        self.roles = [\"soldaat\", \"bootsgezel\", \"adelborst\", \"lanssmissaat\", \"bosschieter\", \"lansmissaat\", \"timmerman\", \"barbier\", \"onderbarbier\", \n",
    "                      \"soldat\", \"sergeant\", \"secretaris\", \"commissaris\", \"tamboer\", \"korporaal\", \"chirurgijn\"]\n",
    "        self.orgs = [\"WIC\", \"W.I.C.\", \"VOC\", \"OIC\", \"V.O.C.\", \"Groenlantse Comp\", \"Admiraliteit\", \"directeurs\", \"heren directeuren\", \"heeren directeuren\", \"particulier\"]\n",
    "        \n",
    "        self.schepen_set = schepen_set\n",
    "        \n",
    "        self.config2 = config2\n",
    "        self.config3 = config3\n",
    "\n",
    "\n",
    "\n",
    "    def extract_sailors(self):\n",
    "        \"\"\"\n",
    "        Extracts Sailor instances from the list of Deed objects provided during the SailorExtractor initialization.\n",
    "        \n",
    "        This method processes each deed, retrieves the corresponding PageXML, and extracts the first few lines of the deed.\n",
    "        It then performs fuzzy matching to identify sailors and their metadata, such as name, location, role, organization, and ship name.\n",
    "        Finally, it returns a list of extracted Sailor instances with the corresponding metadata and additional information for manual checks.\n",
    "        \n",
    "        Returns:\n",
    "            list: A list of Sailor instances extracted from the deeds.\n",
    "        \"\"\"\n",
    "\n",
    "        extracted_sailors = []\n",
    "\n",
    "        number_to_check = len(self.deeds)\n",
    "        c = 0\n",
    "\n",
    "        for deed in self.deeds:\n",
    "            \n",
    "            c += 1\n",
    "            print(f\"Extracting sailors from deed {c} of {number_to_check}\", end=\"\\r\")\n",
    "            pagexml, this_image_url = deed.get_pagexml()\n",
    "            text, fullcoords, dimensions = deed.get_first_lines(pagexml)\n",
    "\n",
    "            if not text:\n",
    "                text = \"\"\n",
    "               \n",
    "            # Get a list of sailors and locations mentioned in this deed\n",
    "            name_to_uri = {person.label: person.person_uri for person in deed.persons}\n",
    "            location_to_uri = {location.label.replace('?', ''): location.location_uri for location in deed.locations} # Remove question marks from location names as fuzzy_search doesn't like them\n",
    "\n",
    "            # ANALYZING FIRST LINES OF DEED USING FUZZY MATCHING\n",
    "            # We will now take a closer look at the first lines of the deed. The sailor_searcher object will\n",
    "            # look for text patterns that might signal the mention of a sailor (\"varende voor\")\n",
    "            # Let's take the most likely match, if there is no match, skip this deed    \n",
    "            match = max(sailor_searcher.find_matches(text), default=None, key=lambda x: x.levenshtein_similarity)\n",
    "\n",
    "            # If there is no match, sometimes \"varende voor\" is attached to other words due to HTR errors\n",
    "            # Try finding this phrase first w/o Phrasesearcher and add spaces before and after the phrase\n",
    "            if not match:\n",
    "                if \"varende voor\" in text:\n",
    "                    # Add an extra space before and after the phrase\n",
    "                    text = text.replace(\"varende voor\", \" varende voor \")\n",
    "                    match = max(sailor_searcher.find_matches(text), default=None, key=lambda x: x.levenshtein_similarity)\n",
    "\n",
    "                elif \"varende\" in text:\n",
    "                    text = text.replace(\"varende\", \" varende voor \")\n",
    "                    match = max(sailor_searcher.find_matches(text), default=None, key=lambda x: x.levenshtein_similarity)\n",
    "\n",
    "            # Try searching for an alternative text pattern\n",
    "            if not match:\n",
    "                match = max(sailor_alt_searcher.find_matches(text), default=None, key=lambda x: x.levenshtein_similarity)\n",
    "            \n",
    "            # Reset variables\n",
    "            interesting_text = \"\"\n",
    "            interesting_text_after = \"\"\n",
    "            sailor_name = None\n",
    "            sailor_uri = None\n",
    "            sailor_location = None\n",
    "            sailor_location_uri = None\n",
    "            sailor_location_htr = None\n",
    "            role = None\n",
    "            sailor_role_htr = None\n",
    "            org = None\n",
    "            org_htr = None\n",
    "            shipname = None\n",
    "            shipname_htr = None\n",
    "\n",
    "            if match:\n",
    "                interesting_text = text[match.offset-70:match.offset].replace(\"Schaef\", \"\") # If Schaef himself is mentioned, delete mention to avoid confusing him with a sailor\n",
    "                interesting_text_after = text[match.offset:match.offset+95]\n",
    "\n",
    "                # Let's see if the one of the names mentioned in the index is mentioned in the deed as a sailor\n",
    "                sailor_name_searcher = FuzzyPhraseSearcher(self.config2)\n",
    "                sailor_name_phrases = list(name_to_uri.keys())\n",
    "                sailor_name_model = PhraseModel(phrases=sailor_name_phrases)\n",
    "                sailor_name_searcher.index_phrase_model(sailor_name_model)\n",
    "                best_sailor_name_match = max(sailor_name_searcher.find_matches(interesting_text), default=None, key=lambda x: x.levenshtein_similarity)\n",
    "                \n",
    "                if best_sailor_name_match:\n",
    "                    sailor_name = best_sailor_name_match.phrase.phrase_string\n",
    "                    sailor_uri = name_to_uri.get(sailor_name)\n",
    "            \n",
    "                # Now let's see if we can find the birthplace for this sailor. It is likely the place mentioned in the \n",
    "                # 'interesting text'. So let's compare this text to the indexed locations from this deed\n",
    "                # create a list of domain keywords and phrases\n",
    "                location_searcher = FuzzyPhraseSearcher(self.config3)\n",
    "                location_phrases = list(location_to_uri.keys())\n",
    "                location_model = PhraseModel(phrases=location_phrases)\n",
    "                location_searcher.index_phrase_model(location_model)\n",
    "                best_location_match = max(location_searcher.find_matches(interesting_text), default=None, key=lambda x: x.levenshtein_similarity)\n",
    "\n",
    "                # If no location is found, try 'Amsterdam' (which was not manually indexed)\n",
    "                if not best_location_match:\n",
    "                    location_phrases = ['amsterdam']\n",
    "                    location_model = PhraseModel(phrases=location_phrases)\n",
    "                    location_searcher.index_phrase_model(location_model)\n",
    "                    best_location_match = max(location_searcher.find_matches(interesting_text), default=None, key=lambda x: x.levenshtein_similarity)\n",
    "                            \n",
    "                if best_location_match:\n",
    "                    sailor_location = best_location_match.phrase.phrase_string\n",
    "                    sailor_location_uri = location_to_uri.get(sailor_location)\n",
    "            \n",
    "                # Let's also see if we can extract the role using only the HTR, without the index\n",
    "                if match.phrase.phrase_string not in no_sailor_job_phrases:\n",
    "                    relevant_fragment = interesting_text_after.lstrip(match.string)\n",
    "                    if len(relevant_fragment) > 0: # Check if the list is not empty\n",
    "                        sailor_role_htr = relevant_fragment.split()[0]\n",
    "                        sailor_role_htr = check_for_empty(sailor_role_htr)\n",
    "                        if sailor_role_htr:\n",
    "                            if len(sailor_role_htr) == 0:\n",
    "                                sailor_role_htr = None\n",
    "\n",
    "                # Also try the organization using regex\n",
    "                org_htr = re.findall(org_pattern, interesting_text_after, re.IGNORECASE)\n",
    "                if len(org_htr) > 0:\n",
    "                    org_htr = org_htr[0]\n",
    "                else:\n",
    "                    org_htr = None\n",
    "\n",
    "                # Now let's see if we can extract the location using only the HTR, without the index\n",
    "                relevant_fragment = interesting_text.split('van')\n",
    "                if len(relevant_fragment) > 1: # Check if the list is not empty\n",
    "                    relevant_fragment = relevant_fragment[-1].split()\n",
    "                    if len(relevant_fragment) > 0: # Check if the string is not empty\n",
    "                        if relevant_fragment[0].lower() == \"st.\":\n",
    "                            sailor_location_htr = relevant_fragment[0] + \" \" + relevant_fragment[1]\n",
    "\n",
    "                        elif len(relevant_fragment) > 2 and relevant_fragment[1].lower() == \"in\":\n",
    "                            sailor_location_htr = relevant_fragment[0] + \" \" + relevant_fragment[1] + \" \" + relevant_fragment[2]\n",
    "\n",
    "                        else:\n",
    "                            sailor_location_htr = relevant_fragment[0]\n",
    "\n",
    "                # Finally, let's try and extract the name of the ship from the HTR, using regex\n",
    "                shipname_htr = re.findall(ship_pattern, text, re.IGNORECASE)\n",
    "                if shipname_htr:\n",
    "                    shipname_htr = shipname_htr[0][1]\n",
    "                    shipname_htr = re.sub(r'\\b(schip|in)\\b', '', shipname_htr, flags=re.IGNORECASE).strip()\n",
    "                    shipname_htr = re.sub(r\"\\b\\w*diens\\w*\\b\", '', shipname_htr, flags=re.IGNORECASE).strip()\n",
    "                else:\n",
    "                    shipname_htr = None\n",
    "\n",
    "            # The subject may have information on the role of the sailor, the organization he was working for and the shipname\n",
    "            if hasattr(deed, \"subject\"):\n",
    "                role = next((role for role in self.roles if role in deed.subject.lower()), None)\n",
    "                org = next((org for org in self.orgs if org.lower() in deed.subject.lower()), None)\n",
    "                possible_ship_mention = deed.subject.lower().split(\"schip\")\n",
    "                if len(possible_ship_mention) > 1:\n",
    "                    shipname = next((shipname for shipname in self.schepen_set if shipname in possible_ship_mention[1].lower()), None)            \n",
    "      \n",
    "            # Create Sailor instances with the extracted information\n",
    "            sailor = Sailor(\n",
    "                deed=deed,\n",
    "                name= sailor_name,\n",
    "                sailor_uri=sailor_uri,\n",
    "                location=sailor_location,\n",
    "                location_uri=sailor_location_uri,\n",
    "                location_htr=sailor_location_htr,\n",
    "                role = role,\n",
    "                role_htr = sailor_role_htr,\n",
    "                organization = org,\n",
    "                organization_htr = org_htr,\n",
    "                shipname = shipname,\n",
    "                shipname_htr = shipname_htr\n",
    "            )\n",
    "\n",
    "            sailor.check =  {\n",
    "                'interesting_text': interesting_text,\n",
    "                'interesting_text_after': interesting_text_after,\n",
    "                'possible_person_labels': list(name_to_uri.keys()),\n",
    "                'possible_location_labels': list(location_to_uri.keys()),\n",
    "                'subject': deed.subject if hasattr(deed, \"subject\") else \"\",\n",
    "                'full_text': text,\n",
    "                'full_coords': calculate_bounding_rectangle(fullcoords) if fullcoords else None,\n",
    "                'dimensions': dimensions if dimensions else None,\n",
    "                'image_url': this_image_url\n",
    "            }\n",
    "\n",
    "            extracted_sailors.append(sailor)\n",
    "        \n",
    "        return extracted_sailors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop\n",
    "Shortcut back to [Config](#Config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting sailors from deed 10 of 10\r"
     ]
    }
   ],
   "source": [
    "# The loop that does all the heavy lifting\n",
    "\n",
    "deed_list = []\n",
    "\n",
    "# A counter for early stopping\n",
    "c = 0\n",
    "start = 0\n",
    "max_count = 10\n",
    "\n",
    "for key, deed in index_schaef_per_deed.items():\n",
    "    c+=1\n",
    "\n",
    "    if c <start:\n",
    "        continue\n",
    "\n",
    "    if 'locations' in deed:\n",
    "        current_deed = Deed(key, deed['date'], deed['subject'], deed['persons'], deed['locations'])\n",
    "    else:\n",
    "        current_deed = Deed(key, deed['date'], deed['subject'], deed['persons'])\n",
    "\n",
    "    deed_list.append(current_deed)\n",
    "    \n",
    "    if c == max_count:\n",
    "        break\n",
    "\n",
    "sailor_extractor = SailorExtractor(deed_list)\n",
    "extracted = sailor_extractor.extract_sailors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deed': <__main__.Deed at 0x7fc261ffed40>,\n",
       " 'sailor_uri': 'https://archief.amsterdam/indexen/deeds/d0092ad0-9919-1a7b-e053-b784100aab8a?person=123020bd-a145-88e7-3a32-879f2e3f4cec',\n",
       " 'name': 'Frans Scherhoen',\n",
       " 'location': None,\n",
       " 'location_uri': None,\n",
       " 'location_htr': 'Roesbiug',\n",
       " 'role': 'soldaat',\n",
       " 'role_htr': None,\n",
       " 'organization': 'WIC',\n",
       " 'organization_htr': None,\n",
       " 'shipname': None,\n",
       " 'shipname_htr': 'Stant van',\n",
       " 'check': {'interesting_text': '. ende In presentie etc. Frans Schekoen van Roesbiug Teelofte Soldaet ',\n",
       "  'interesting_text_after': 'opt Schip Stant van In dienst etc. Ende bekende etc. schuldich te wesen aen Andrietgen Barents ',\n",
       "  'possible_person_labels': ['Frans Scherhoen',\n",
       "   'Pr Pietersz Draeijer',\n",
       "   'Annetgen Barents'],\n",
       "  'possible_location_labels': ['Roesbrugge'],\n",
       "  'subject': 'Soldaat, WIC.',\n",
       "  'full_text': \"Op Huijden den 14en. Januarij 1636 e ontrent halff nunnen voor noen. Compe. ende In presentie etc. Frans Schekoen van Roesbiug Teelofte Soldaet opt Schip Stant van In dienst etc. Ende bekende etc. schuldich te wesen aen Andrietgen Barents huijsvrou van Pr. Pietersz draeijer, desomme van Eenhondert sar: gl. Doer veiteerde P tot uijtansti soste ende verschoor pden ence  het adsignad. ende transpat etc. Onder verbant etc. Gedaen t' Amsterdam ter presentie van Adian als schagen ende Gerrit Jansz\",\n",
       "  'full_coords': [[18, 134], [2533, 134], [2533, 1746], [18, 1746]],\n",
       "  'dimensions': [2605, 3958],\n",
       "  'image_url': 'AJVUHENHOPYWPJVEKVOOSSMI'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted[1].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn extracted into a dataframe\n",
    "sailor_dicts = []\n",
    "for sailor in extracted:\n",
    "    sailor_dict = {\n",
    "        'deed_uri': sailor.deed.deed_uri,\n",
    "        'deed_date': sailor.deed.date,\n",
    "        'name': sailor.name,\n",
    "        'location': sailor.location,\n",
    "        'role': sailor.role,\n",
    "        'organization': sailor.organization,\n",
    "        'ship_name': sailor.shipname,\n",
    "        'location_htr': sailor.location_htr,\n",
    "        'role_htr': sailor.role_htr,\n",
    "        'organization_htr': sailor.organization_htr,\n",
    "        'ship_name_htr': sailor.shipname_htr,\n",
    "        'sailor_uri': sailor.sailor_uri,\n",
    "        'location_uri': sailor.location_uri,\n",
    "        'interesting_text': sailor.check['interesting_text'],\n",
    "        'interesting_text_after': sailor.check['interesting_text_after'],\n",
    "        'possible_names': sailor.check['possible_person_labels'],\n",
    "        'possible_locations': sailor.check['possible_location_labels'],\n",
    "        'subject': sailor.check['subject'],\n",
    "        'text': sailor.check['full_text'],\n",
    "        'full_coords': sailor.check['full_coords'],\n",
    "        'dimensions': sailor.check['dimensions'],\n",
    "        'image_url': sailor.check['image_url']\n",
    "    }\n",
    "    sailor_dicts.append(sailor_dict)\n",
    "\n",
    "    sailors_df = pd.DataFrame(sailor_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store sailors as a csv\n",
    "current_datetime = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "sailors_df.index.name = 'no.'\n",
    "sailors_df.to_csv(f'sailors-{current_datetime}.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "db3ad00c254152fbd946dfe3ddf750e2d6dd1f511dd85499e770b0c6b301697a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
