{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Om te beginnen laden we de gecureerde versie van de WIC-opvarenden database in\n",
    "opvarenden_curated = pd.read_excel('validated 6.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tijdelijk: we verwijderen gesplitste data ('/') uit de dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter alle rijen met '/' erin ...\n",
    "columns_to_check_excluding_role = ['name', 'location', 'ship_name', 'organization', 'captain', 'Bestemming', 'final_creditor_name', 'final_debt_amount_int']\n",
    "rows_to_remove = opvarenden_curated[opvarenden_curated[columns_to_check_excluding_role].apply(lambda x: x.str.contains('/')).any(axis=1)]\n",
    "\n",
    "# ... en verwijder die!\n",
    "opvarenden_curated = opvarenden_curated.drop(rows_to_remove.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eerst proberen we de namen van schuldeisers te normaliseren aan de hand van een vooraf voorbereide lijst\n",
    "normalized_creditors = {}\n",
    "with open('normalized_creditors_gdk.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile, delimiter=';')\n",
    "    next(reader) # header\n",
    "    for row in reader:\n",
    "        if row[1].strip():  # Check  of row[1] niet leeg is\n",
    "            normalized_creditors[row[0]] = row[1]\n",
    "\n",
    "opvarenden_curated['normalized_creditor_name'] = opvarenden_curated['final_creditor_name'].map(normalized_creditors)\n",
    "opvarenden_curated['normalized_creditor_name'] = opvarenden_curated['normalized_creditor_name'].fillna(opvarenden_curated['final_creditor_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nu hetzelfde voor schepen\n",
    "normalized_ships = {}\n",
    "with open('normalized_ships_gdk.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile, delimiter=';')\n",
    "    next(reader) # header\n",
    "    for row in reader:\n",
    "        normalized_ships[row[0]] = row[1]\n",
    "\n",
    "opvarenden_curated['normalized_ship_name'] = opvarenden_curated['ship_name'].map(normalized_ships)\n",
    "opvarenden_curated['normalized_ship_name'] = opvarenden_curated['normalized_ship_name'].fillna(opvarenden_curated['ship_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nu laden we de locaties in \n",
    "temp_locations = pd.read_excel('normalized_locations_gdk.xlsx')\n",
    "\n",
    "# Eerst maken we een lijst met alle unieke locaties\n",
    "unique_locations = temp_locations[['place_standardized', 'country_code', 'geonames_uri', 'latitude', 'longitude']].drop_duplicates()\n",
    "\n",
    "# er zitten nog wat NaNs in\n",
    "unique_locations = unique_locations.dropna(subset=['place_standardized', 'geonames_uri'])\n",
    "\n",
    "# We gebruiken betere namen voor de kolommen\n",
    "Locations = unique_locations.rename(columns={\n",
    "    'place_standardized': 'label',\n",
    "    'country_code': 'country',\n",
    "    'geonames_uri': 'geonames_uri',\n",
    "    'latitude': 'latitude',\n",
    "    'longitude': 'longitude'\n",
    "})\n",
    "\n",
    "# We geven iedere locatie een id\n",
    "Locations.insert(0, 'location_id', range(1, 1 + len(Locations)))\n",
    "\n",
    "# Dict om (label, geonames_uri) naar location_id te mappen\n",
    "location_to_index = { (row['label'], row['geonames_uri']): row['location_id'] for _, row in Locations.iterrows() }\n",
    "\n",
    "# wic_location geeft een link naar de locatie \n",
    "temp_locations['wic_location'] = temp_locations.apply(lambda row: location_to_index.get((row['place_standardized'], row['geonames_uri']), None) if pd.notna(row['place_standardized']) and pd.notna(row['geonames_uri']) else None, axis=1)\n",
    "\n",
    "# Tijdelijk? Voor locaties zonder Geonames koppeling, maar wel een country_code\n",
    "new_locations = pd.DataFrame([\n",
    "    {'location_id': 2000, 'label': 'Frankrijk (land)', 'country': 'FR', 'geonames_uri': 'http://sws.geonames.org/3017382/', 'latitude': 46.603354, 'longitude': 1.888334},\n",
    "    {'location_id': 2001, 'label': 'Ierland (land)', 'country': 'IE', 'geonames_uri': 'http://sws.geonames.org/2963597/', 'latitude': 53.41291, 'longitude': -8.24389},\n",
    "    {'location_id': 2002, 'label': 'Groot-Brittannië (land)', 'country': 'GB', 'geonames_uri': 'http://sws.geonames.org/2635167/', 'latitude': 54.7023545, 'longitude': -3.2765753},\n",
    "    {'location_id': 2003, 'label': 'Nederland (land)', 'country': 'NL', 'geonames_uri': 'http://sws.geonames.org/2750405/', 'latitude': 52.5, 'longitude': 5.75},\n",
    "    {'location_id': 2004, 'label': 'België (land)', 'country': 'BE', 'geonames_uri': 'http://sws.geonames.org/2802361/', 'latitude': 50.5, 'longitude': 4.5},\n",
    "    {'location_id': 2005, 'label': 'Noorwegen (land)', 'country': 'NO', 'geonames_uri': 'http://sws.geonames.org/3144096/', 'latitude': 60.472024, 'longitude': 8.468946},\n",
    "    {'location_id': 2006, 'label': 'Zweden (land)', 'country': 'SE', 'geonames_uri': 'http://sws.geonames.org/2661886/', 'latitude': 60.128161, 'longitude': 18.643501},\n",
    "    {'location_id': 2007, 'label': 'Duitsland (land)', 'country': 'DE', 'geonames_uri': 'http://sws.geonames.org/2921044/', 'latitude': 51.0834196, 'longitude': 10.4234469},\n",
    "    {'location_id': 2008, 'label': 'Denemarken (land)', 'country': 'DK', 'geonames_uri': 'http://sws.geonames.org/2623032/', 'latitude': 56.26392, 'longitude': 9.501785},\n",
    "    {'location_id': 2009, 'label': 'Finland (land)', 'country': 'FI', 'geonames_uri': 'http://sws.geonames.org/660013/', 'latitude': 61.92411, 'longitude': 25.748151},\n",
    "])\n",
    "Locations = pd.concat([Locations, new_locations], ignore_index=True)\n",
    "\n",
    "# zorg dat wic_locatie een integer is\n",
    "temp_locations['wic_location'] = temp_locations['wic_location'].astype('Int64')\n",
    "\n",
    "# Reset index\n",
    "Locations = Locations.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nu gaan we aparte tabellen maken voor entiteiten, te beginnen met personen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We maken een df voor Personen en voegen notaris Henrick Schaeff handmatig toe\n",
    "Persons = pd.DataFrame(columns=['person_id', 'name', 'uri', 'role', 'location_string', 'location_uri'])\n",
    "henrick = pd.DataFrame({\n",
    "    'person_id': [1],\n",
    "    'name': ['Henrick Schaeff'],\n",
    "    'uri': [''],\n",
    "    'role': ['notary'],\n",
    "    'location_string': [''],\n",
    "    'location_uri': ['']\n",
    "})\n",
    "Persons = pd.concat([Persons, henrick], ignore_index=True)\n",
    "\n",
    "# df voor akten\n",
    "Deeds = pd.DataFrame(columns=['deed_id', 'deed_uri', 'notary_id', 'deed_date'])\n",
    "\n",
    "# df voor transacties\n",
    "Transactions = pd.DataFrame(columns=['deed_id', 'sailor_id', 'creditor_id', 'final_debt_amount_int'])\n",
    "\n",
    "# We voeden bovenstaande dfs met data uit de ingeladen WIC-opvarenden database\n",
    "person_id_counter = Persons['person_id'].max() + 1\n",
    "deed_id_counter = 1\n",
    "\n",
    "for index, row in opvarenden_curated.iterrows():\n",
    "    sailors = row['name'].split('/')\n",
    "    sailor_uri = row['sailor_uri'] if pd.notna(row['sailor_uri']) else ''\n",
    "    creditors = str(row['normalized_creditor_name']).split('/') if pd.notna(row['normalized_creditor_name']) else []\n",
    "    deed_uri = row['deed_uri'] if pd.notna(row['deed_uri']) else ''\n",
    "    final_debt_amount_int = row['final_debt_amount_int']\n",
    "    deed_date = row['correct_deed_date'] if pd.notna(row['correct_deed_date']) else row['deed_date']\n",
    "    location_string = row['location'] if pd.notna(row['location']) else ''\n",
    "    location_uri = row['location_uri'] if pd.notna(row['location_uri']) else ''\n",
    "    \n",
    "    # Sailors gaan altijd naar Persons (geen check of ze dubbel zijn)\n",
    "    for sailor in sailors:\n",
    "        person = pd.DataFrame({\n",
    "            'person_id': [person_id_counter],\n",
    "            'name': [sailor],\n",
    "            'uri': [sailor_uri if len(sailors) == 1 else ''],\n",
    "            'role': ['sailor'],\n",
    "            'location_string': [location_string],\n",
    "            'location_uri': [location_uri]\n",
    "        })\n",
    "        Persons = pd.concat([Persons, person], ignore_index=True)\n",
    "        sailor_id = person_id_counter\n",
    "        person_id_counter += 1\n",
    "    \n",
    "    # Voor schuldeisers (die heel vaak voorkomen en gestandaardiseerde namen hebben) wel een check\n",
    "    for creditor in creditors:\n",
    "        existing_creditor = Persons[(Persons['name'] == creditor) & (Persons['role'] == 'creditor')]\n",
    "        if existing_creditor.empty:\n",
    "            person = pd.DataFrame({\n",
    "                'person_id': [person_id_counter],\n",
    "                'name': [creditor],\n",
    "                'uri': [''],\n",
    "                'role': ['creditor'],\n",
    "                'location_string': [''],\n",
    "                'location_uri': ['']\n",
    "            })\n",
    "            Persons = pd.concat([Persons, person], ignore_index=True)\n",
    "            creditor_id = person_id_counter\n",
    "            person_id_counter += 1\n",
    "        else:\n",
    "            creditor_id = existing_creditor['person_id'].values[0]\n",
    "    \n",
    "    # Voeg de akte toe aan Deeds\n",
    "    deed = pd.DataFrame({\n",
    "        'deed_id': [deed_id_counter],\n",
    "        'deed_uri': [deed_uri],\n",
    "        'notary_id': [1],  # Henrick Schaeff is 1\n",
    "        'deed_date': [deed_date]\n",
    "    })\n",
    "    Deeds = pd.concat([Deeds, deed], ignore_index=True)\n",
    "    deed_id = deed_id_counter\n",
    "    deed_id_counter += 1\n",
    "    \n",
    "    # Transacties tussen opvarenden en schuldeisers gaan naar Transactions\n",
    "    for sailor in sailors:\n",
    "        for creditor in creditors:\n",
    "            transaction = pd.DataFrame({\n",
    "                'deed_id': [deed_id],\n",
    "                'sailor_id': [sailor_id],\n",
    "                'creditor_id': [creditor_id],\n",
    "                'final_debt_amount_int': [final_debt_amount_int]\n",
    "            })\n",
    "            Transactions = pd.concat([Transactions, transaction], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voeg de locaties toe aan de Persons DataFrame\n",
    "Persons['location_standardized'] = None\n",
    "\n",
    "# Dict om deed_id naar deed_uri te mappen voor snelle toegang\n",
    "deed_id_to_uri = Deeds.set_index('deed_id')['deed_uri'].to_dict()\n",
    "\n",
    "# We itereren over iedere persoon in Persons ...\n",
    "for idx, person in Persons[Persons['role'] == 'sailor'].iterrows():\n",
    "    sailor_id = person['person_id']\n",
    "    # ... zoeken naar de gekoppelde transacties ...\n",
    "    sailor_transactions = Transactions[Transactions['sailor_id'] == sailor_id]\n",
    "    for _, transaction in sailor_transactions.iterrows():\n",
    "        deed_id = transaction['deed_id']\n",
    "        deed_uri = deed_id_to_uri.get(deed_id, None)\n",
    "        if deed_uri:\n",
    "            # ... en zoeken naar de locatie van de schuldeiser\n",
    "            temp_location_matches = temp_locations[(temp_locations['deed_uri'] == deed_uri) & (temp_locations['name'] == person['name'])]\n",
    "            if not temp_location_matches.empty:\n",
    "                # als er meerdere matches zijn, kies de eerste\n",
    "                wic_location = temp_location_matches.iloc[0]['wic_location']\n",
    "                country_code = temp_location_matches.iloc[0]['country_code']\n",
    "                if pd.notna(wic_location):\n",
    "                    Persons.at[idx, 'location_standardized'] = wic_location\n",
    "                    break # we hebben een match gevonden, dus we kunnen stoppen\n",
    "\n",
    "                # Tijdelijke (?) oplossing voor locaties zonder Geonames koppeling\n",
    "                if pd.isna(wic_location) & pd.notna(country_code):\n",
    "                    if country_code == 'FR':\n",
    "                        Persons.at[idx, 'location_standardized'] = 2000\n",
    "                    elif country_code == 'IE':\n",
    "                        Persons.at[idx, 'location_standardized'] = 2001\n",
    "                    elif country_code == 'GB':\n",
    "                        Persons.at[idx, 'location_standardized'] = 2002\n",
    "                    elif country_code == 'NL':\n",
    "                        Persons.at[idx, 'location_standardized'] = 2003\n",
    "                    elif country_code == 'BE':\n",
    "                        Persons.at[idx, 'location_standardized'] = 2004\n",
    "                    elif country_code == 'NO':\n",
    "                        Persons.at[idx, 'location_standardized'] = 2005\n",
    "                    elif country_code == 'SE':\n",
    "                        Persons.at[idx, 'location_standardized'] = 2006\n",
    "                    elif country_code == 'DE':\n",
    "                        Persons.at[idx, 'location_standardized'] = 2007\n",
    "                    elif country_code == 'DK':\n",
    "                        Persons.at[idx, 'location_standardized'] = 2008\n",
    "                    elif country_code == 'FI':\n",
    "                        Persons.at[idx, 'location_standardized'] = 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nu gaan we individuele reizen van schepen in een aparte tabel zetten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1319/2918634750.py:21: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  opvarenden_curated_updated = opvarenden_curated.groupby(['normalized_ship_name', 'organization']).apply(detect_voyages).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# We werken met oude datums, dus deed date moet een string zijn\n",
    "opvarenden_curated['deed_date'] = opvarenden_curated['deed_date'].astype(str)\n",
    "\n",
    "# Initialiseer counter voor Voyages\n",
    "global_voyage_id = 0\n",
    "\n",
    "# Functie om afzonderlijke reizen te detecteren\n",
    "def detect_voyages(group):\n",
    "    global global_voyage_id\n",
    "    group = group.sort_values('deed_date').reset_index(drop=True)\n",
    "    if pd.notna(group['normalized_ship_name'].iloc[0]):  # Is er een genormaliseerde schipnaam?\n",
    "        group['deed_date_period'] = group['deed_date'].apply(lambda x: pd.Period(x, freq='D'))\n",
    "        group['voyage_id'] = group['deed_date_period'].diff().apply(lambda x: x.n > 180 if pd.notna(x) else False).cumsum() # meer dan 180 dagen verschil? nieuwe reis!\n",
    "        group['voyage_id'] += global_voyage_id\n",
    "        global_voyage_id = group['voyage_id'].max() + 1  # id ophogen\n",
    "    else:\n",
    "        group['voyage_id'] = pd.NA  # NA als er geen genormaliseerde schipnaam is\n",
    "    return group\n",
    "\n",
    "# We voeren deze functie uit voor iedere combinatie van schip en organisatie\n",
    "opvarenden_curated_updated = opvarenden_curated.groupby(['normalized_ship_name', 'organization']).apply(detect_voyages).reset_index(drop=True)\n",
    "\n",
    "# Aanmaken Voyages df\n",
    "Voyages = opvarenden_curated_updated.groupby('voyage_id').agg(\n",
    "    ship_name=('normalized_ship_name', 'first'),\n",
    "    organization=('organization', 'first'),\n",
    "    first_deed_date=('deed_date', 'first'),\n",
    "    last_deed_date=('deed_date', 'last')\n",
    ").reset_index()\n",
    "\n",
    "# Updaten opvarenden_curated met nieuwe informatie\n",
    "opvarenden_curated = opvarenden_curated_updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nu voegen we de Voyage_ids to aan Transactions\n",
    "Transactions['voyage_id'] = None\n",
    "\n",
    "# Dict om deed_id naar uri te mappen voor snelle lookup\n",
    "deed_id_to_uri = pd.Series(Deeds.deed_uri.values, index=Deeds.deed_id).to_dict()\n",
    "\n",
    "# Dict omt uri naar voayge id te mappen voor snelle lookup\n",
    "deed_uri_to_voyage_id = pd.Series(opvarenden_curated_updated.voyage_id.values, index=opvarenden_curated_updated.deed_uri).to_dict()\n",
    "\n",
    "# Update voyage_id in Transactions\n",
    "for index, row in Transactions.iterrows():\n",
    "    deed_id = row['deed_id']\n",
    "    if deed_id in deed_id_to_uri:\n",
    "        deed_uri = deed_id_to_uri[deed_id]\n",
    "        if deed_uri in deed_uri_to_voyage_id:\n",
    "            Transactions.at[index, 'voyage_id'] = deed_uri_to_voyage_id[deed_uri]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zorg dat location_standardized een integer is\n",
    "Persons['location_standardized'] = Persons['location_standardized'].astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu hebben we alle afzonderlijke dataframes. Tijd om een SQLite-database te maken!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('wic-opvarenden.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Drop tables als ze al bestaan\n",
    "cursor.execute('DROP TABLE IF EXISTS Deeds')\n",
    "cursor.execute('DROP TABLE IF EXISTS Locations')\n",
    "cursor.execute('DROP TABLE IF EXISTS Persons')\n",
    "cursor.execute('DROP TABLE IF EXISTS Transactions')\n",
    "cursor.execute('DROP TABLE IF EXISTS Voyages')\n",
    "\n",
    "# Maak benodigde tables aan (inclusief foreign key-relaties)\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS Deeds (\n",
    "        deed_id INTEGER PRIMARY KEY,\n",
    "        deed_uri TEXT,\n",
    "        notary_id INTEGER,\n",
    "        deed_date TEXT,\n",
    "        FOREIGN KEY (notary_id) REFERENCES Persons(person_id)\n",
    "    )\n",
    "''')\n",
    "\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS Locations (\n",
    "        location_id INTEGER PRIMARY KEY,\n",
    "        label TEXT,\n",
    "        country TEXT,\n",
    "        geonames_uri TEXT,\n",
    "        latitude REAL,\n",
    "        longitude REAL\n",
    "    )\n",
    "''')\n",
    "\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS Persons (\n",
    "        person_id INTEGER PRIMARY KEY,\n",
    "        name TEXT,\n",
    "        uri TEXT,\n",
    "        role TEXT,\n",
    "        location_string TEXT,\n",
    "        location_uri TEXT,\n",
    "        location_standardized INTEGER,\n",
    "        FOREIGN KEY (location_standardized) REFERENCES Locations(location_id)\n",
    "    )\n",
    "''')\n",
    "\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS Transactions (\n",
    "        deed_id INTEGER,\n",
    "        sailor_id INTEGER,\n",
    "        creditor_id INTEGER,\n",
    "        final_debt_amount_int INTEGER,\n",
    "        voyage_id INTEGER,\n",
    "        FOREIGN KEY (deed_id) REFERENCES Deeds(deed_id),\n",
    "        FOREIGN KEY (sailor_id) REFERENCES Persons(person_id),\n",
    "        FOREIGN KEY (creditor_id) REFERENCES Persons(person_id),\n",
    "        FOREIGN KEY (voyage_id) REFERENCES Voyages(voyage_id)\n",
    "    )\n",
    "''')\n",
    "\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS Voyages (\n",
    "        voyage_id INTEGER PRIMARY KEY,\n",
    "        ship_name TEXT,\n",
    "        organization TEXT,\n",
    "        first_deed_date TEXT,\n",
    "        last_deed_date TEXT\n",
    "    )\n",
    "''')\n",
    "\n",
    "# Dat uit df inlezen in de database\n",
    "Deeds.to_sql('Deeds', conn, if_exists='append', index=False)\n",
    "Locations.to_sql('Locations', conn, if_exists='append', index=False)\n",
    "Persons.to_sql('Persons', conn, if_exists='append', index=False)\n",
    "Transactions.to_sql('Transactions', conn, if_exists='append', index=False)\n",
    "Voyages.to_sql('Voyages', conn, if_exists='append', index=False)\n",
    "\n",
    "# Commit en close\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
